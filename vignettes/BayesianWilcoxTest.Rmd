---
title: "A Bayesian Alternative to the Wilcoxon Rank Test"
author: "Joachim Reinhardt"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: Rbibliography.bib
vignette: >
  %\VignetteIndexEntry{A Bayesian Alternative to the Wilcoxon Rank Test}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

The **bayesWilcoxTest** R-package implements a Bayesian Alternative to the classical
Wilcoxon Rank test and is intended as an addition to the **BayesianFirstAid** 
package [@baath2014bayesian]. As in the original Wilcoxon test, the data are 
substituted by their ranks. Following @gelman2014bayesian, p. 97, the ranks
are then transformed to the quantiles of a standard Gaussian
distribution. This allows modeling the transformed data as a Gaussian
distribution via Bayesian methods with uninformative priors. The resulting 
posterior distribution can be interpreted similarly to the classical hypothesis
test, but provides more detailed information and has a more straightforward
interpretation.  
The package implements a paired and independent sample test.  

## Introduction

In a frequentist framework, hypothesis testing is performed in a way that is
distinct from other forms of inference, such as parameter estimation. In a 
frequentist hypothesis test, the compability of the observed data with a given
hypothesis on model parameters is assessed, while parameter estimation - for 
example by maximum likelihood methods - is concerned with finding the parameter
estimate most compatible with the given data. In probability notation, 
frequentist hypothesis tests evaluate $P(y|\theta_0)$, known as the p-value -
i.e. the probability of obtaining the observed data $y$ under the assumption 
that the model under the null hypothesis, with parameters $\theta_0$, is the 
true process by which the data are generated. Frequentist maximum likelihood 
parameter estimation operates by finding the value of $\theta$ for 
which the likelihood ${\cal L}(\theta|y)$ given the observed data is maximal, 
which corresponds to the parameter with a p-value of $1$, or $P(y|\theta) = 1$.
  
  
From a Bayesian perspective, parameter estimates and hypothesis tests on 
parameters both involve the same estimation procedure. The outcome of 
Bayesian model estimation is a full probability distribution of the parameters
in question, the posterior distribution $P(\theta|y)$. This posterior 
distribution can directly be employed to test hypotheses on the parameters at 
hand.  

One way of doing so are Bayes factors, which compare the posterior distributions
of two models, usually under a null and an alternative hypothesis. The ratio of
both posterior distributions indicates which model can be considered likely 
given the observed data. A major difference to frequentist hypothesis tests is
that evidence both for and against the null hypothesis is considered; thus, the
equivalent of "accepting" the null hypothesis is possible. The drawback of 
using Bayes Factors for hypothesis testing is that they can only be usefully 
employed for clearly discrete alternatives of parameter values, as noted by
@gelman2014bayesian, p. 182. For continuous models with infinitely many 
parameter values between alternative hypotheses, the use of Bayes factors is not
helpful.  

### The BEST Approach

Another way of Bayesian hypothesis testing is presented by 
@kruschke2013bayesian, who describes a Bayesian alternative to the
frequentist t-test. This approach was extended to different types of hypothesis
tests in the **BayesianFirstAid** R-package [@baath2014bayesian], and this the 
approach followed for the **bayesWilcoxTest** package. Kruschke's BEST
("Bayesian Estimation Supersedes the t Test") procedure for the two-sample test
models the data as Student's t distributions with uninformative priors. The 
resulting posterior distributions for the $\mu$ parameter of both groups give 
the probabilies of the means exceeding or falling below any given value, and 
the probability of their differences ...  
Advantages of this testing procedure, etc.  

### The Frequentist Wilcoxon

Hypothesis tests such as the frequentist t-Test and BEST are based on the 
assumption that the data follow a Gaussian (for the frequentist test) or a 
Student's t distribution (for BEST). In addition, the scale of measurement of 
the data needs to be an interval scale, which excludes data on an 
ordinal scale such as grades or ratings. For cases in which these assumptions
are violated, non-parametric alternatives exist: the Wilcoxon Signed Rank test
for paired samples, due to @wilcoxon1945individual, and the independent-sample
Wilcoxon Rank Sum test, also known as the Mann-Whitney test, first proposed by
@wilcoxon1945individual and further developed by @mann1947test.


  

In the following, a similar Bayesian testing procedure for the frequentist 
Wilcoxon Rank test will be presented.



## The Bayesian Wilcoxon Rank Test

The present section describes the estimation procedure for Bayesian Alternative 
to the frequentist Wilcoxon Rank test which is implemented by the
**bayes.wilcox.test** package.

### Nonlinear transformation to Gaussian quantiles

The Bayesian Wilcoxon test follows an estimation procedure outlined in 
@gelman2014bayesian and further described in a blog post by Andrew Gelman
[@gelman2015dont] for a two-sample test. As in the frequentist Wilcoxon 
procedure, the data are substituted by their ranks. Subsequently, the ranks
are transformed to quantiles of a standard Gaussian distribution by applying a
Gaussian quantile function to the sequence  

$$\frac{1}{2n}, \frac{3}{2n}, ..., \frac{2i-1}{2n}, ..., \frac{2n - 1}{2n}$$

which results in a discrete distribution which approaches a standard Gaussian 
distribution as $n$ increases. A similar approach has been proposed 
by @van1953neuer, who suggested using a sequence of equidistant points instead 
of the sequence (). The differences between the resulting transformed ranks for
two groups can in turn be modeled as a Gaussian distribution.  
Via Bayesian estimation, a model with uninformative priors can be estimated in
order to obtain a BEST-style hypothesis test.

### Prior Distributions

For the two-sample case, both groups are modeled as independent Gaussian 
distributions. Thus, prior distributions for the mean and variance of both 
groups are required. In order to keep these priors uninformative, uniform 
distributions are employed, and since the distribution of the transformed ranks
is known and depends only on the sample size, the upper and lower limits of the
prior distributions can be derived.  

For the variance, the lower limit is zero, since it is possible that all data
from one group have the same value, resulting in the assignment of tied ranks 
which are all equal and thus a variance of zero. The maximum variance is 
realized if one group consists only of two data points, which at the same time
are the highest and lowest value of both groups combined. The transformed ranks
assigned to these two values depend on the overall sample size. The smallest 
transformed rank is given by $Z_{min} = \Phi^{-1}(\frac{1}{2n})$, the largest by 
$Z_{max} = \Phi^{-1}(\frac{2n-1}{2n})$. Due to the symmetry of the Gaussian 
quantile function, $Z_{min} = -Z_{max}$, which implies a zero mean for the two 
values. The maximum variance is thus given by  

$$\sigma^2_{max}(n) = \frac{1}{2}(\Phi^{-1}(\frac{2n-1}{2n}))^2 + 
\frac{1}{2}(\Phi^{-1}(\frac{2n-1}{2n}))^2 = (\Phi^{-1}(\frac{2n-1}{2n}))^2$$ 

which results in a maximum standard deviation of 
$\sigma_{max}(n) = \Phi^{-1}(\frac{2n-1}{2n}) = -\Phi^{-1}(\frac{1}{2n})$.  

The lowest possible mean for one of the two groups is realized if this group
again consists only of two data points, which are the two lowest values of the
overall data. Their transformed ranks would then be given by 
$Z_{min1} = \Phi^{-1}(\frac{1}{2n})$ and $Z_{min2} = \Phi^{-1}(\frac{3}{2n})$,
resulting in a lowest possible mean of  

$$\mu_{min}(n) =  \frac{1}{2}(\Phi^{-1}(\frac{1}{2n}) +
\Phi^{-1}(\frac{3}{2n}))$$

and, due to symmetry of the quantile function, a highest possible mean of  

$$\mu_{max}(n) =  -\frac{1}{2}(\Phi^{-1}(\frac{1}{2n}) +
\Phi^{-1}(\frac{3}{2n}))$$  

The priors on the means for both groups are thus given by a uniform distribution
... Since the 

For the paired sample test, the single target posterior distribution is the 
difference between the transformed ranks of both groups. Again, uniformly
distributed priors are employed for the mean and variance.  

In the paired sample case, the variance depends on the ordering of the 
observations in the two groups.
A value of zero can be realized if all values in the first 
group are smaller than all values in the second group, and both groups are 
sorted in ascending order. The difference in transformed ranks would then be
the same for all pairs of values, resulting in a smallest possible variance of 
zero.  
As the variance depends on the ordering of the observations, the largest
possible variance is more difficult to estimate exactly. The maximum variance of
the differences in transformed ranks is larger than the variance of the 
individual transformed ranks, thus, a larger upper limit than in the two-sample
case is required.  
**bayesWilcoxTest** uses the range of the transformed ranks as a rough estimate
of the upper limit of the standard deviation, since the standard deviation 
cannot exceed this value here. The range of the transformed ranks is, due to 
symmetry, twice the largest of the transformed rank values, i.e.
$$ \sigma_{max}(n) = 2\Phi^{-1}(\frac{2n-1}{2n}) = -2\Phi^{-1}(\frac{1}{2n})$$

The largest and smallest possible mean of the differences in transformed ranks
can be obtained in a more straightforward fashion. The smallest mean will be 
realized if all elements in $x$ are larger than all values in $y$, and vice 
versa - due to symmetry, $\mu_{min} = -\mu_{max}$. Calculating the possible 
means for $x > y$ for different sample sizes reveals that $\mu_{max}$ converges
to a value just below $1.6$:
```{r}
pairDiff_means <- function(N) {
  #create x and y so that x > y
  x <- seq(1.1, 2.1, by = (1/(N - 1)))
  y <- seq(0, 1, by = (1/(N - 1)))
  n <- length(x) + length(y)
  ranks <- rank(c(x, y)) # Replace by ranks
  #Tranformed Ranks
  seqQ <- seq(1, 2*n - 1, by = 2)/(2*n)
  zRanks <- qnorm(seqQ[ranks])
  zRanksX <- zRanks[1:length(x)]
  zRanksY <- zRanks[-(1:length(x))]
  mean_diff <- mean(zRanksX - zRanksY)
  return(mean_diff)
}
means <- c()
for (i in 2:500) {
  means <- c(means, pairDiff_means(i))
}
plot(means, type = "l", ylab = "mu_max",  xlab = "N")
```

The upper and lower limits of the unifrom prior distribution for the mean of
transformed differences are thus $\mu_{min} = -1.6$ and $\mu_{max} = 1.6$.

For both the paired and independent sample case, initial values for the MCMC
are set to $\mu = 0$ and $\sigma = 1$, i.e., the values which are obtained 
under the null hypothesis.

## The bayes.wilcox.test Package



## Notes

[@gelman2011bayesian, p.11]: "Even the Wilcoxon Test is based on assumptions!"

Note: Consider Mann-Whitney Test! -> test for two independent groups, also
included in wilcox.test function

Gelman (blog post): "the Wilcoxon test has a huge assumption which is that the 
distributions are identical in the two groups. This is a much more important 
assumption than normality." Cite blog post

"History of the idea": [@van1953neuer] introduced concept, but used equidistant
points instead of quantiles. [@gelman2014bayesian, p. 97] using quantiles

[@kruschke2013bayesian, p. 575]: "In the case of data from a single
group, including the case of a single group of difference scores
from repeated measures on the same subjects, a modified model
merely estimates $\mu$, $\sigma$, and $\nu$ of the group." Crucial change from
independent two paired sample test: two different $\sigma$s vs. a single one
See Kruschke's 2011 discussion of oneway / twoway ANOVA!

Consider including effect size / How to deal with mu?



## References
